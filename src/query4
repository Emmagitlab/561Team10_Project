/**
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */
package org.apache.hadoop.examples;


import java.io.IOException;
import java.util.StringTokenizer;
import java.util.Arrays;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.FloatWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.io.LongWritable;

public class Query4 {

    public static class TokenizerMapper
            extends Mapper<Object, Text, LongWritable, Text> {

        private final static Text info = new Text();
        private LongWritable custID = new LongWritable();

        public void map(Object key, Text value, Reducer.Context context
        ) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            String token;
            String tuple[];
            String[][] c = null;
            String[][] t = null;
            int cCount = 0;
            int tCount = 0;
            String val = null;
  

            while (itr.hasMoreTokens()) {
                token = itr.nextToken();
                tuple = token.split(",");
                if(tuple[1].matches("^[A-Za-z]+$"))
                {
                    c[cCount][0] = tuple[0];
                    c[cCount][1] = tuple[3];
                    c[cCount][2] = "0";
                    cCount ++;
                    
                }
                else{
                    
                    t[tCount][0] = tuple[1];
                    t[tCount][1] = tuple[2];
                    t[tCount][2] = "1";
                    tCount++;
                
                }
                
               
            }
            
          for(int i=0; i < cCount; i++){
          
              for (int j=0; j < tCount; j++){
              
                  if(c[i][0].equals(t[j][0])){
                      
                  
                      t[j][2] = c[i][1];
                      custID.set(Long.parseLong(t[j][0]));
                      val = t[j][1] + ","+t[j][2];
                      info.set(val);
                      context.write(custID, val);
                      
                  
                  
                  }
              
              
              }
          
          
          }  
          
         
            
          
        }
    }

//    public static class TokenizerMapper2
//            extends Mapper<Object, Text, LongWritable, Text> {
//
//        private final static Text transInfo = new Text();
//        private final LongWritable custID = new LongWritable();
//
//        public void map(Object key, Text value, Reducer.Context context
//        ) throws IOException, InterruptedException {
//            StringTokenizer itr = new StringTokenizer(value.toString());
//            String token;
//            String tuple[];
//
//            while (itr.hasMoreTokens()) {
//                token = itr.nextToken();
//                tuple = token.split(",");
//                custID.set(Long.parseLong(tuple[1]));
//                transInfo.set(tuple[2] + ","+"1" );
//                context.write(custID, transInfo);
//                // System.out.println(itr.toString());
//            }
//        }
//    }

    public static class TransTotalReducer
            extends Reducer<LongWritable, Text, LongWritable, Text> {

        private Text result = new Text();
        private LongWritable key1 = new LongWritable();

        public void reduce(Text key, Iterable<Text> values,
                Context context
        ) throws IOException, InterruptedException {
            
            
            String outkey = null;
            String record = null;
            String[] info = null;
            int[] countCust = null;
            int countryCode = 0;
            float[] maxTotal= null;
            float[] minTotal= null;
            float total = 0;
            float max = 0;
            float min =9999;
            
            
            
            for (Text val : values) {
                info = (val.toString()).split(",");
                countryCode = Integer.parseInt(info[0]);
                switch(countryCode){ 
                   case 1: countCust[0]++;
                   maxTotal[0]=compareMax(total,max);
                   minTotal[0]= compareMin(total,min);
                   break;
                   case 2: countCust[1]++;
                   maxTotal[1]=compareMax(total,max);
                   minTotal[1]=compareMin(total,min);                   
                   break;
                   case 3: countCust[2]++;
                   maxTotal[2]=compareMax(total,max);
                   minTotal[2]=compareMin(total,min);
                   break;
                   case 4: countCust[3]++;
                   maxTotal[3]=compareMax(total,max);
                   minTotal[3]= compareMin(total,min);
                   break;
                   case 5: countCust[4]++;
                   maxTotal[4]= compareMax(total,max);
                   minTotal[4]= compareMin(total,min);
                   break;
                   case 6: countCust[5]++;
                   maxTotal[5]= compareMax(total,max);
                   minTotal[5]= compareMin(total,min);
                   break;
                   case 7: countCust[6]++;
                   maxTotal[6]= compareMax(total,max);
                   minTotal[6]=compareMin(total,min);
                   break;
                   case 8: countCust[7]++;
                   maxTotal[7]= compareMax(total,max);
                   minTotal[7]=compareMin(total,min);
                   break;
                   case 9: countCust[8]++;
                   maxTotal[8]= compareMax(total,max);
                   minTotal[8]=compareMin(total,min);
                   break;
                   case 10: countCust[9]++;
                   maxTotal[9]= compareMax(total,max);
                   minTotal[9]=compareMin(total,min);
                   break;
                }
                
            }
            

            
            for (int n=0; n < 10; n++){
                outkey = Integer.toString(n+1);
                record = countCust[n]+","+ maxTotal[n]+","+ minTotal[n];
                key1.set(Long.parseLong(outkey));
                result.set(record);
                context.write(key1, result);
            }
            
        }
        public float compareMax(float total, float max){
        
            if (total > max){

                max = total;
            }
           return max; 
        
        }

        public float compareMin(float total, float min){
        
            if (total < min){

                min = total;
            }
           return min; 
        
        }
        
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        if (args.length != 3) {
            System.err.println("Usage: query4 <HDFS input file1> <HDFS input file2> <HDFS output file>");
            System.exit(2);
        }
        Job job = new Job(conf, "query4");
        job.setJarByClass(Query4.class);
        //job.setMapperClass(TokenizerMapper.class);
        //job.setMapperClass(TokenizerMapper2.class);
        //job.setCombinerClass(FloatSumReducer.class);
        job.setReducerClass(TransTotalReducer.class);
        job.setNumReduceTasks(6);
        job.setOutputKeyClass(LongWritable.class);
        job.setOutputValueClass(Text.class);
        job.setMapOutputKeyClass(LongWritable.class);
        job.setMapOutputValueClass(Text.class);


        MultipleInputs.addInputPath(job, new Path(args[0]), TextInputFormat.class, TokenizerMapper.class);
        MultipleInputs.addInputPath(job, new Path(args[1]), TextInputFormat.class, TokenizerMapper.class);
        FileOutputFormat.setOutputPath(job, new Path(args[2]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
